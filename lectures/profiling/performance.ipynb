{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a7cba59-f646-4dcc-b491-57bb37b193ec",
   "metadata": {},
   "source": [
    "# Performance\n",
    "We already discussed that performance is stochastic, *i.,e.,* sequential runnings of the same program can lead to different execution times. Recapitulating, we can measure:\n",
    "- **Counts** of how often an event occurs.\n",
    "- The **duration** of some interval.\n",
    "- The **size** of a given variable.\n",
    "\n",
    "We are going to discuss next how we measure performance using Python.\n",
    "\n",
    "## Measuring CPU time\n",
    "### `timeit`\n",
    "This module can be used to measure the execution time of a piece of code. In particular, it can be called from the terminal to be executed under a .py file using\n",
    "```bash\n",
    "python -m timeit my_script.py\n",
    "python -m timeit \"My Python code\"\n",
    "```\n",
    "In a Jupyter Notebook, we do it using the **magic function** `%timeit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367a8aa1-27c2-4027-9d93-5fe2715f5e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f67665-851b-45df-a12f-92e27c9659b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit [x**4 for x in range(10000)]\n",
    "%timeit np.arange(10000)**4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5ba0e4-9897-4800-9965-7cb1f06be996",
   "metadata": {},
   "source": [
    "As you can see, an approach to beat the stochastic CPU time is to use statistics. The output of this magic function shows the mean and standard deviation after running the subsequent code a number of times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3effad91-c039-4be0-b34d-dfda82b8b4f5",
   "metadata": {},
   "source": [
    "We can also measure the execution CPU time of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd621119-086c-495f-b7b6-abb89371018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit # Now it applies to the entire cell\n",
    "def sum2d(arr):\n",
    "    M, N = arr.shape\n",
    "    result = 0.0\n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "            result += arr[i,j]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30c587e-2f99-4bc7-8939-58bd6ae1351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The previous script does not define the function\n",
    "def sum2d(arr):\n",
    "    M, N = arr.shape\n",
    "    result = 0.0\n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "            result += arr[i,j]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9bcb4e-a4f9-4f4f-b315-6c362ff517e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.ones((2048,2048)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5906d0-3a01-4043-a884-25bee343a3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.size == 2048 ** 2 # elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a91e070-7a2a-4d0a-bfce-f08edf5a820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit sum2d(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27785bd-2b70-46f9-b84f-eb6f9737de64",
   "metadata": {},
   "source": [
    "### `njit from numba`\n",
    "The `njit` function from the Numba library is used for **Just-In-Time (JIT) compilation of Python code** to achieve significant performance improvements. `Numba` is a Just-In-Time compiler for Python that translates your Python functions into optimized machine code, often resulting in execution speeds comparable to compiled languages like C and Fortran.\n",
    "\n",
    "**Note.** The old function `jit` is now deprecated. See [here](https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ae70a6-9863-40f7-a4ea-f3138788becc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be98bb7-d665-4804-af12-ccab2c47c832",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.ones((2048,2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c096384-ed48-4e9e-9e06-d17aae36338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def sum2dv3(arr):\n",
    "    M, N = arr.shape\n",
    "    result = 0.0\n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "            result += arr[i,j]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5defdc-7f1a-4dee-84ef-b4938f3dccc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit sum2d(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db9581-698a-4bc1-801d-09dd97aaef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit sum2dv3(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2958fe1-0226-49cc-a6c8-442cff90f462",
   "metadata": {},
   "source": [
    "Amazing!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd0df9a-e62c-4898-b8a6-99de10facf46",
   "metadata": {},
   "source": [
    "### `numexpr`\n",
    "The `numexpr` library in Python is designed to efficiently evaluate numerical expressions on arrays. It provides a way to accelerate numerical computations, especially those involving large arrays, by optimizing memory usage and utilizing multiple CPU cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ab651b-f770-443e-8e4d-670e1a83704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numexpr as ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d666da-8806-4a07-95f2-2d6b5c890e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(100000)\n",
    "b = np.random.rand(100000)\n",
    "%timeit np.sin(a) + np.log(b)\n",
    "%timeit ne.evaluate(\"sin(a) + log(b)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83477d05-78bb-4a57-bd26-ba18cedfe99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit 2*a + 3*b\n",
    "%timeit ne.evaluate(\"2*a + 3*b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f938949-6eb9-4a43-9634-9db5ab947431",
   "metadata": {},
   "source": [
    "## Measuring Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b6408e-eedc-4f0f-875e-ceb5aae27f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1.3, 2.4, 3.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef019ab7-0fa1-41e4-8ee7-c02c63cb1061",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.data # Memory Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82fc32f-ad88-4ef6-8ede-d655ecff477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'data' = A 2-tuple whose first argument is a \n",
    "# Python integer that points to the data-area storing the array contents.\n",
    "x.__array_interface__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9befd8b-9588-4822-a48b-148e85def62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size (number of elements of the array)\n",
    "x.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7cb8d8-ccbe-49a0-8008-0744bef0b287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory size of one array element (in bytes)\n",
    "x.itemsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a30564-c355-4786-869e-f6ca11ebda13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory size of the full (in bytes)\n",
    "x.itemsize * x.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc085b2-0f54-4da6-bca2-9101577b6c21",
   "metadata": {},
   "source": [
    "## Profiling\n",
    "Profiling in Python involves analyzing the performance of your code to identify bottlenecks and areas that can be optimized for better efficiency. Python offers several tools and libraries for profiling code. Here we are going to cover some considered native (*i.,e.,* that do not require additional software).\n",
    "\n",
    "### `cProfile`\n",
    "**syntax (on bash)**\n",
    "```bash\n",
    "python -m cProfile my_script.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968997bc-c328-408a-a8fe-8e857963fc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import system # module to work with bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4130815-04c6-4bae-a16c-c93945b65a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system(\"cat examples/Example0.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4340cc-badf-4f92-8804-c4c2381cb2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "system(\"python -m cProfile examples/Example0.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16eccdbb-5fee-4fa8-b129-98fab4e5e513",
   "metadata": {},
   "source": [
    "What are we seeing?\n",
    "- `ncalls`: This column shows the number of times each function was called during the execution of the program.\n",
    "- `tottime`: This column indicates the total time (in seconds) spent in each function excluding time spent in its subfunctions. It's the \"internal\" time spent exclusively in the function itself.\n",
    "- `percall`: This column shows the average time (in seconds) spent in each function call, calculated as tottime / ncalls.\n",
    "- `cumtime`: This column represents the cumulative time (in seconds) spent in the function and all its subfunctions. It includes the time spent in the function itself and all the functions called from it.\n",
    "- `percall`: This column indicates the average cumulative time (in seconds) per call, calculated as cumtime / ncalls.\n",
    "- `filename:lineno(function)`: This column provides information about the location of the function in your code, including the filename, line number, and function name.\n",
    "\n",
    "The output is generally sorted by the cumtime column, which helps you quickly identify functions that consume the most overall time. These are potential candidates for optimization. You will want to look at functions with **high cumtime and ncalls values**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e300df3-d717-4c77-8521-314f31fa28df",
   "metadata": {},
   "source": [
    "### `profile`\n",
    "The `profile` module is another built-in profiler that provides a higher-level interface for profiling your code. It outputs information about function calls and their time consumption. You can use the `profile` module to profile specific parts of your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac490b1-eea1-45d2-a395-0381f51e3130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9406696-f4a5-4be0-a865-6f7ef2c63fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\tx=[1.0]*(2048*2048) \n",
    "\ta=str(x[0]) \n",
    "\ta+=\" is a one...\" \n",
    "\tdel x\t\t\t\n",
    "\tprint(a)\n",
    "\n",
    "profiler = profile.Profile()\n",
    "profiler.runcall(main)\n",
    "profiler.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45ddbf3-8a25-461f-b68f-4307f38b8974",
   "metadata": {},
   "source": [
    "We are still getting an output similar to `cProfile`. To get an output of the performance line-by-line, we should do something else.\n",
    "1. Install `line_profiler` using `pip` or `anaconda`.\n",
    "2. On the .py file that you want to analyze, put the decorator `@profile` above the function that you want to profile.\n",
    "3. Use `kernprof.py` (found [here](https://github.com/pyutils/line_profiler/blob/main/kernprof.py), but also inside `examples`) on your .py file.\n",
    "4. Execute the command \n",
    "```bash\n",
    "python -m profile my_script.py\n",
    "```\n",
    "\n",
    "Try to do this for the example files in `examples/`\n",
    "\n",
    "There is also a way to do it locally. Bear with me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8585d48a-dc61-420b-8906-870260d2a2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from line_profiler import LineProfiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa529bd-90e1-468b-a35e-2ee5eb299e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(a,b,c):\n",
    "\tprint(\"a= \", a)\n",
    "\tprint(\"b= \", b)\n",
    "\tprint(np.dot(a,b))\n",
    "\tprint(a @ b)\n",
    "\n",
    "a = np.array([[1,2],[4,3]])\n",
    "b = np.array([[1,2],[4,3]])\n",
    "c = np.arange(2) + 1\n",
    "\n",
    "lp = LineProfiler()\n",
    "lp_wrapper = lp(main)\n",
    "lp_wrapper(a,b,c)\n",
    "lp.print_stats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
