{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e969880-5cd6-4cad-b860-72fb0b26bf41",
   "metadata": {},
   "source": [
    "# Pytorch\n",
    "Before introducing PyTorch, we will first implement the network using numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57804b9-1c96-4941-bdb5-21c58afbb6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Create random input and output data\n",
    "x = np.linspace(-math.pi, math.pi, 2000)\n",
    "y = np.sin(x)\n",
    "\n",
    "# Randomly initialize weights\n",
    "a = np.random.randn()\n",
    "b = np.random.randn()\n",
    "c = np.random.randn()\n",
    "d = np.random.randn()\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    # Forward pass: compute predicted y\n",
    "    # y = a + b x + c x^2 + d x^3\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of a, b, c, d with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_a = grad_y_pred.sum()\n",
    "    grad_b = (grad_y_pred * x).sum()\n",
    "    grad_c = (grad_y_pred * x ** 2).sum()\n",
    "    grad_d = (grad_y_pred * x ** 3).sum()\n",
    "\n",
    "    # Update weights\n",
    "    a -= learning_rate * grad_a\n",
    "    b -= learning_rate * grad_b\n",
    "    c -= learning_rate * grad_c\n",
    "    d -= learning_rate * grad_d\n",
    "\n",
    "print(f'Result: y = {a} + {b} x + {c} x^2 + {d} x^3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bf772a-aa86-4a6f-b77e-6926edc1b4a3",
   "metadata": {},
   "source": [
    "üöÄ PyTorch Tensors and GPU Acceleration\n",
    "üí° Why Not Just NumPy?\n",
    "\n",
    "While NumPy is a powerful tool for numerical computing, it has two key limitations when it comes to modern deep learning:\n",
    "\n",
    "    ‚ùå No GPU support: NumPy operations run only on the CPU.\n",
    "\n",
    "    ‚ùå No automatic gradient tracking: You must manually compute gradients.\n",
    "\n",
    "    Modern deep learning often sees 50x or greater speedups with GPUs ‚Äî making NumPy insufficient for training large models.\n",
    "\n",
    "‚ö° Enter PyTorch Tensors\n",
    "‚úÖ What is a Tensor?\n",
    "\n",
    "A PyTorch Tensor is conceptually the same as a NumPy array ‚Äî it's an n-dimensional array, but with superpowers:\n",
    "\n",
    "    ‚úÖ GPU-compatible\n",
    "\n",
    "    ‚úÖ Gradient-aware (can build computation graphs)\n",
    "\n",
    "    ‚úÖ Drop-in NumPy-like syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4f2f14-f813-4520-a9c6-5204310f08b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "\n",
    "# Create random input and output data\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# Randomly initialize weights\n",
    "a = torch.randn((), device=device, dtype=dtype)\n",
    "b = torch.randn((), device=device, dtype=dtype)\n",
    "c = torch.randn((), device=device, dtype=dtype)\n",
    "d = torch.randn((), device=device, dtype=dtype)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    # Forward pass: compute predicted y\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of a, b, c, d with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_a = grad_y_pred.sum()\n",
    "    grad_b = (grad_y_pred * x).sum()\n",
    "    grad_c = (grad_y_pred * x ** 2).sum()\n",
    "    grad_d = (grad_y_pred * x ** 3).sum()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    a -= learning_rate * grad_a\n",
    "    b -= learning_rate * grad_b\n",
    "    c -= learning_rate * grad_c\n",
    "    d -= learning_rate * grad_d\n",
    "\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac09b583-334d-4ffb-8590-5d9da33fd819",
   "metadata": {},
   "source": [
    "ü§ñ Automatic Differentiation with autograd in PyTorch\n",
    "üß† Why Use Autograd?\n",
    "\n",
    "In the previous examples, we manually computed gradients. That works for small models, but it gets complex and error-prone in larger networks.\n",
    "üöÄ Enter autograd ‚Äî PyTorch‚Äôs Automatic Differentiation Engine\n",
    "\n",
    "    PyTorch builds a computational graph during the forward pass.\n",
    "\n",
    "    Each Tensor is a node, and operations are edges.\n",
    "\n",
    "    Calling .backward() on the final loss triggers backpropagation through the graph.\n",
    "\n",
    "    Gradients are automatically computed and stored in .grad.\n",
    "\n",
    "‚ú® Benefits of Autograd\n",
    "Feature\tManual Gradients\tAutograd\n",
    "Scalability\t‚ùå Hard to scale\t‚úÖ Easy\n",
    "Readability\t‚ùå Verbose\t‚úÖ Clean\n",
    "Error-prone\t‚úÖ Very\t‚ùå No\n",
    "Automatic graph building\t‚ùå\t‚úÖ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee274dc3-7e53-4e02-a017-5ff52c03d2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "# We want to be able to train our model on an `accelerator <https://pytorch.org/docs/stable/torch.html#accelerators>`__\n",
    "# such as CUDA, MPS, MTIA, or XPU. If the current accelerator is available, we will use it. Otherwise, we use the CPU.\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "torch.set_default_device(device)\n",
    "\n",
    "# Create Tensors to hold input and outputs.\n",
    "# By default, requires_grad=False, which indicates that we do not need to\n",
    "# compute gradients with respect to these Tensors during the backward pass.\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# Create random Tensors for weights. For a third order polynomial, we need\n",
    "# 4 weights: y = a + b x + c x^2 + d x^3\n",
    "# Setting requires_grad=True indicates that we want to compute gradients with\n",
    "# respect to these Tensors during the backward pass.\n",
    "a = torch.randn((), dtype=dtype, requires_grad=True)\n",
    "b = torch.randn((), dtype=dtype, requires_grad=True)\n",
    "c = torch.randn((), dtype=dtype, requires_grad=True)\n",
    "d = torch.randn((), dtype=dtype, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    # Forward pass: compute predicted y using operations on Tensors.\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    # Compute and print loss using operations on Tensors.\n",
    "    # Now loss is a Tensor of shape (1,)\n",
    "    # loss.item() gets the scalar value held in the loss.\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Use autograd to compute the backward pass. This call will compute the\n",
    "    # gradient of loss with respect to all Tensors with requires_grad=True.\n",
    "    # After this call a.grad, b.grad. c.grad and d.grad will be Tensors holding\n",
    "    # the gradient of the loss with respect to a, b, c, d respectively.\n",
    "    loss.backward()\n",
    "\n",
    "    # Manually update weights using gradient descent. Wrap in torch.no_grad()\n",
    "    # because weights have requires_grad=True, but we don't need to track this\n",
    "    # in autograd.\n",
    "    with torch.no_grad():\n",
    "        a -= learning_rate * a.grad\n",
    "        b -= learning_rate * b.grad\n",
    "        c -= learning_rate * c.grad\n",
    "        d -= learning_rate * d.grad\n",
    "\n",
    "        # Manually zero the gradients after updating weights\n",
    "        a.grad = None\n",
    "        b.grad = None\n",
    "        c.grad = None\n",
    "        d.grad = None\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90115675-81d9-417c-a574-c02a3b9d9d9a",
   "metadata": {},
   "source": [
    "# üõ†Ô∏è Custom Autograd Functions in PyTorch\n",
    "\n",
    "Under the hood, each primitive autograd operator is really two functions that operate on Tensors:  \n",
    "\n",
    "- The **forward** function computes output Tensors from input Tensors.  \n",
    "- The **backward** function receives the gradient of the output Tensors with respect to some scalar value, and computes the gradient of the input Tensors with respect to that same scalar value.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ú® Defining a Custom Autograd Operator\n",
    "\n",
    "In PyTorch, we can easily define our own autograd operator by subclassing `torch.autograd.Function` and implementing the `forward()` and `backward()` methods.\n",
    "\n",
    "Once defined, we can use our new autograd operator by constructing an instance and calling it like a regular function, passing in Tensors.\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Example: Using Legendre Polynomial $ P_3(x) = \\frac{1}{2}(5x^3 - 3x) $\n",
    "\n",
    "We define our model as:\n",
    "\n",
    "$$\n",
    "y = a + b \\cdot P_3(c + d \\cdot x)\n",
    "$$\n",
    "\n",
    "instead of:\n",
    "\n",
    "$$\n",
    "y = a + bx + cx^2 + dx^3\n",
    "$$\n",
    "\n",
    "We'll write a custom autograd function for computing the forward and backward passes of $ P_3(x) $, and use it in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2091d11c-0b43-4896-bc65-b4ac51e1d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "\n",
    "class LegendrePolynomial3(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    We can implement our own custom autograd Functions by subclassing\n",
    "    torch.autograd.Function and implementing the forward and backward passes\n",
    "    which operate on Tensors.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \"\"\"\n",
    "        In the forward pass we receive a Tensor containing the input and return\n",
    "        a Tensor containing the output. ctx is a context object that can be used\n",
    "        to stash information for backward computation. You can cache arbitrary\n",
    "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        return 0.5 * (5 * input ** 3 - 3 * input)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
    "        with respect to the output, and we need to compute the gradient of the loss\n",
    "        with respect to the input.\n",
    "        \"\"\"\n",
    "        input, = ctx.saved_tensors\n",
    "        return grad_output * 1.5 * (5 * input ** 2 - 1)\n",
    "\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\")  # Uncomment this to run on GPU\n",
    "\n",
    "# Create Tensors to hold input and outputs.\n",
    "# By default, requires_grad=False, which indicates that we do not need to\n",
    "# compute gradients with respect to these Tensors during the backward pass.\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# Create random Tensors for weights. For this example, we need\n",
    "# 4 weights: y = a + b * P3(c + d * x), these weights need to be initialized\n",
    "# not too far from the correct result to ensure convergence.\n",
    "# Setting requires_grad=True indicates that we want to compute gradients with\n",
    "# respect to these Tensors during the backward pass.\n",
    "a = torch.full((), 0.0, device=device, dtype=dtype, requires_grad=True)\n",
    "b = torch.full((), -1.0, device=device, dtype=dtype, requires_grad=True)\n",
    "c = torch.full((), 0.0, device=device, dtype=dtype, requires_grad=True)\n",
    "d = torch.full((), 0.3, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "learning_rate = 5e-6\n",
    "for t in range(2000):\n",
    "    # To apply our Function, we use Function.apply method. We alias this as 'P3'.\n",
    "    P3 = LegendrePolynomial3.apply\n",
    "\n",
    "    # Forward pass: compute predicted y using operations; we compute\n",
    "    # P3 using our custom autograd operation.\n",
    "    y_pred = a + b * P3(c + d * x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Use autograd to compute the backward pass.\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    with torch.no_grad():\n",
    "        a -= learning_rate * a.grad\n",
    "        b -= learning_rate * b.grad\n",
    "        c -= learning_rate * c.grad\n",
    "        d -= learning_rate * d.grad\n",
    "\n",
    "        # Manually zero the gradients after updating weights\n",
    "        a.grad = None\n",
    "        b.grad = None\n",
    "        c.grad = None\n",
    "        d.grad = None\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} * P3({c.item()} + {d.item()} x)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12259d81-2095-46f8-997f-77dfee75540f",
   "metadata": {},
   "source": [
    "# üß± Building Neural Networks with `nn.Module` in PyTorch\n",
    "\n",
    "Computational graphs and autograd are a very powerful paradigm for defining complex operators and automatically taking derivatives. However, for large neural networks, **raw autograd can be a bit too low-level**.\n",
    "\n",
    "---\n",
    "\n",
    "## üîº Layer Abstractions\n",
    "\n",
    "When building neural networks, we often think in terms of **layers** ‚Äî many of which have **learnable parameters**. High-level frameworks help simplify this:\n",
    "\n",
    "- **TensorFlow**: Keras, TensorFlow-Slim, TFLearn\n",
    "- **PyTorch**: `torch.nn`\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ The `nn` Package in PyTorch\n",
    "\n",
    "The `nn` package provides:\n",
    "\n",
    "- A set of **Modules** (i.e., layers)\n",
    "- Built-in **loss functions**\n",
    "- A convenient way to structure and manage **model parameters**\n",
    "\n",
    "A `Module` in PyTorch:\n",
    "- Receives input Tensors\n",
    "- Computes output Tensors\n",
    "- May hold internal **learnable parameters** (like weights and biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37d7abc-6a17-40f2-8ed6-42a383c897a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "# Create Tensors to hold input and outputs.\n",
    "x = torch.linspace(-math.pi, math.pi, 2000)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# For this example, the output y is a linear function of (x, x^2, x^3), so\n",
    "# we can consider it as a linear layer neural network. Let's prepare the\n",
    "# tensor (x, x^2, x^3).\n",
    "p = torch.tensor([1, 2, 3])\n",
    "xx = x.unsqueeze(-1).pow(p)\n",
    "xx.shape\n",
    "# In the above code, x.unsqueeze(-1) has shape (2000, 1), and p has shape\n",
    "# (3,), for this case, broadcasting semantics will apply to obtain a tensor\n",
    "# of shape (2000, 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8906ea6-07af-4f96-b935-f2b9b1f2ae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
    "# is a Module which contains other Modules, and applies them in sequence to\n",
    "# produce its output. The Linear Module computes output from input using a\n",
    "# linear function, and holds internal Tensors for its weight and bias.\n",
    "# The Flatten layer flatens the output of the linear layer to a 1D tensor,\n",
    "# to match the shape of `y`.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(3, 1),\n",
    "    torch.nn.Flatten(0, 1)\n",
    ")\n",
    "\n",
    "# The nn package also contains definitions of popular loss functions; in this\n",
    "# case we will use Mean Squared Error (MSE) as our loss function.\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "\n",
    "    # Forward pass: compute predicted y by passing x to the model. Module objects\n",
    "    # override the __call__ operator so you can call them like functions. When\n",
    "    # doing so you pass a Tensor of input data to the Module and it produces\n",
    "    # a Tensor of output data.\n",
    "    y_pred = model(xx)\n",
    "\n",
    "    # Compute and print loss. We pass Tensors containing the predicted and true\n",
    "    # values of y, and the loss function returns a Tensor containing the\n",
    "    # loss.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Zero the gradients before running the backward pass.\n",
    "    model.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to all the learnable\n",
    "    # parameters of the model. Internally, the parameters of each Module are stored\n",
    "    # in Tensors with requires_grad=True, so this call will compute gradients for\n",
    "    # all learnable parameters in the model.\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the weights using gradient descent. Each parameter is a Tensor, so\n",
    "    # we can access its gradients like we did before.\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= learning_rate * param.grad\n",
    "\n",
    "# You can access the first layer of `model` like accessing the first item of a list\n",
    "linear_layer = model[0]\n",
    "\n",
    "# For linear layer, its parameters are stored as `weight` and `bias`.\n",
    "print(f'Result: y = {linear_layer.bias.item()} + {linear_layer.weight[:, 0].item()} x + {linear_layer.weight[:, 1].item()} x^2 + {linear_layer.weight[:, 2].item()} x^3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090bda8e-ea9b-4f9b-a8af-ece9190f0b7c",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è Using Optimizers from `torch.optim`\n",
    "\n",
    "Up to this point, we have updated the weights of our models by **manually mutating the Tensors** holding learnable parameters using `torch.no_grad()`.  \n",
    "\n",
    "This approach is fine for simple optimizers like **stochastic gradient descent (SGD)**, but in practice we often use more advanced algorithms such as:\n",
    "\n",
    "- ‚úÖ AdaGrad  \n",
    "- ‚úÖ RMSProp  \n",
    "- ‚úÖ Adam  \n",
    "- ‚úÖ Others...\n",
    "\n",
    "---\n",
    "\n",
    "## üß∞ The `torch.optim` Package\n",
    "\n",
    "PyTorch's `optim` package:\n",
    "\n",
    "- Abstracts the concept of an **optimization algorithm**\n",
    "- Provides **built-in implementations** of many popular optimizers\n",
    "- Automatically handles parameter updates and internal states (like momentum, adaptive learning rates, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be398e9-177e-48c3-a1d5-082c6e782edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "\n",
    "# Create Tensors to hold input and outputs.\n",
    "x = torch.linspace(-math.pi, math.pi, 2000)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# Prepare the input tensor (x, x^2, x^3).\n",
    "p = torch.tensor([1, 2, 3])\n",
    "xx = x.unsqueeze(-1).pow(p)\n",
    "\n",
    "# Use the nn package to define our model and loss function.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(3, 1),\n",
    "    torch.nn.Flatten(0, 1)\n",
    ")\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "# Use the optim package to define an Optimizer that will update the weights of\n",
    "# the model for us. Here we will use RMSprop; the optim package contains many other\n",
    "# optimization algorithms. The first argument to the RMSprop constructor tells the\n",
    "# optimizer which Tensors it should update.\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "for t in range(2000):\n",
    "    # Forward pass: compute predicted y by passing x to the model.\n",
    "    y_pred = model(xx)\n",
    "\n",
    "    # Compute and print loss.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables it will update (which are the learnable\n",
    "    # weights of the model). This is because by default, gradients are\n",
    "    # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
    "    # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to model\n",
    "    # parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "linear_layer = model[0]\n",
    "print(f'Result: y = {linear_layer.bias.item()} + {linear_layer.weight[:, 0].item()} x + {linear_layer.weight[:, 1].item()} x^2 + {linear_layer.weight[:, 2].item()} x^3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c741d7c-4e12-442e-b9de-c92fb80f017f",
   "metadata": {},
   "source": [
    "# üß© Custom `nn.Module` Subclasses for Flexible Model Definitions\n",
    "\n",
    "Sometimes you‚Äôll want to specify models that are **more complex than a simple stack** of layers (`nn.Sequential`).  \n",
    "For these cases, you can create a **custom Module** by subclassing `nn.Module` and defining your own `forward()` method.\n",
    "\n",
    "This approach gives you **complete flexibility** to:\n",
    "\n",
    "- Use other modules (like layers or activations)\n",
    "- Combine them in arbitrary ways\n",
    "- Mix in raw `autograd` operations as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f649dee4-2907-4fd9-bac1-a3b6f17ac135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "\n",
    "class Polynomial3(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate four parameters and assign them as\n",
    "        member parameters.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.a = torch.nn.Parameter(torch.randn(()))\n",
    "        self.b = torch.nn.Parameter(torch.randn(()))\n",
    "        self.c = torch.nn.Parameter(torch.randn(()))\n",
    "        self.d = torch.nn.Parameter(torch.randn(()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Tensor of input data and we must return\n",
    "        a Tensor of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Tensors.\n",
    "        \"\"\"\n",
    "        return self.a + self.b * x + self.c * x ** 2 + self.d * x ** 3\n",
    "\n",
    "    def string(self):\n",
    "        \"\"\"\n",
    "        Just like any class in Python, you can also define custom method on PyTorch modules\n",
    "        \"\"\"\n",
    "        return f'y = {self.a.item()} + {self.b.item()} x + {self.c.item()} x^2 + {self.d.item()} x^3'\n",
    "\n",
    "\n",
    "# Create Tensors to hold input and outputs.\n",
    "x = torch.linspace(-math.pi, math.pi, 2000)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = Polynomial3()\n",
    "\n",
    "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
    "# in the SGD constructor will contain the learnable parameters (defined \n",
    "# with torch.nn.Parameter) which are members of the model.\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-6)\n",
    "for t in range(2000):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'Result: {model.string()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbcfd76-2b58-48ec-bba6-127d87eb8207",
   "metadata": {},
   "source": [
    "# üîÑ Dynamic Graphs & Weight Sharing in PyTorch\n",
    "\n",
    "One of PyTorch‚Äôs standout features is its use of **dynamic computational graphs**, meaning the graph is built **on-the-fly** during each forward pass.  \n",
    "This makes it extremely flexible and **compatible with native Python control flow** like loops, conditionals, etc.\n",
    "\n",
    "Another powerful feature is **weight sharing**: you can reuse the same `nn.Parameter` multiple times across your model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabeabbb-5917-475e-8627-187f49ad9c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import math\n",
    "\n",
    "\n",
    "class DynamicNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate five parameters and assign them as members.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.a = torch.nn.Parameter(torch.randn(()))\n",
    "        self.b = torch.nn.Parameter(torch.randn(()))\n",
    "        self.c = torch.nn.Parameter(torch.randn(()))\n",
    "        self.d = torch.nn.Parameter(torch.randn(()))\n",
    "        self.e = torch.nn.Parameter(torch.randn(()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        For the forward pass of the model, we randomly choose either 4, 5\n",
    "        and reuse the e parameter to compute the contribution of these orders.\n",
    "\n",
    "        Since each forward pass builds a dynamic computation graph, we can use normal\n",
    "        Python control-flow operators like loops or conditional statements when\n",
    "        defining the forward pass of the model.\n",
    "\n",
    "        Here we also see that it is perfectly safe to reuse the same parameter many\n",
    "        times when defining a computational graph.\n",
    "        \"\"\"\n",
    "        y = self.a + self.b * x + self.c * x ** 2 + self.d * x ** 3\n",
    "        for exp in range(4, random.randint(4, 6)):\n",
    "            y = y + self.e * x ** exp\n",
    "        return y\n",
    "\n",
    "    def string(self):\n",
    "        \"\"\"\n",
    "        Just like any class in Python, you can also define custom method on PyTorch modules\n",
    "        \"\"\"\n",
    "        return f'y = {self.a.item()} + {self.b.item()} x + {self.c.item()} x^2 + {self.d.item()} x^3 + {self.e.item()} x^4 ? + {self.e.item()} x^5 ?'\n",
    "\n",
    "\n",
    "# Create Tensors to hold input and outputs.\n",
    "x = torch.linspace(-math.pi, math.pi, 2000)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = DynamicNet()\n",
    "\n",
    "# Construct our loss function and an Optimizer. Training this strange model with\n",
    "# vanilla stochastic gradient descent is tough, so we use momentum\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-8, momentum=0.9)\n",
    "for t in range(30000):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    if t % 2000 == 1999:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'Result: {model.string()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2209b6f5-6e8f-46f2-9599-d87a1fff6646",
   "metadata": {},
   "source": [
    "# TorchVision Object Detection Finetuning Tutorial\n",
    "\n",
    "In this tutorial, we will fine-tune a pre-trained [Mask R-CNN](https://arxiv.org/abs/1703.06870) model on the [Penn-Fudan Database for Pedestrian Detection and Segmentation](https://www.cis.upenn.edu/~jshi/ped_html/). The dataset contains 170 images with 345 instances of pedestrians. We'll use it to demonstrate how to fine-tune a pre-trained object detection and instance segmentation model on a custom dataset.\n",
    "\n",
    "## Defining the Dataset\n",
    "\n",
    "TorchVision's object detection, instance segmentation, and keypoint detection training scripts are designed to easily support new custom datasets. To use your own dataset, follow these steps:\n",
    "\n",
    "### Dataset Requirements\n",
    "\n",
    "The dataset should inherit from the standard `torch.utils.data.Dataset` class and implement `__len__` and `__getitem__` methods. The `__getitem__` method should return a tuple:\n",
    "\n",
    "- **image**: A tensor of shape `[3, H, W]` (or a PIL image of size `(H, W)`).\n",
    "- **target**: A dictionary containing:\n",
    "  - `boxes`: A tensor of shape `[N, 4]` containing bounding box coordinates in the format `[x0, y0, x1, y1]` (ranging from `0` to `W` and `0` to `H`).\n",
    "  - `labels`: A tensor of shape `[N]` containing the label for each bounding box (with class `0` representing the background).\n",
    "  - `image_id`: An integer identifier for the image, unique across the dataset, used during evaluation.\n",
    "  - `area`: A tensor of shape `[N]` containing the area of each bounding box, used during evaluation to differentiate between small, medium, and large boxes.\n",
    "  - `iscrowd`: A tensor of shape `[N]` indicating which instances are considered \"crowd\" and should be ignored during evaluation.\n",
    "  - (Optionally) `masks`: A tensor of shape `[N, H, W]` containing segmentation masks for each object.\n",
    "\n",
    "If your dataset follows these rules, it will work with both training and evaluation scripts from the reference implementation. Evaluation uses `pycocotools`, which can be installed using:\n",
    "\n",
    "```bash\n",
    "pip install pycocotools\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4323d056-3ae5-4a77-9482-e38263ac8dcd",
   "metadata": {},
   "source": [
    "## Handling Labels\n",
    "\n",
    "The model considers `0` as the background class. If your dataset doesn't include a background class, ensure that `0` is not present in your labels. For example, if you have two classes, *cat* and *dog*, you should define:\n",
    "\n",
    "- `1` as *cat*\n",
    "- `2` as *dog*\n",
    "\n",
    "For an image containing both classes, the `labels` tensor would look like this: `[1, 2]`.\n",
    "\n",
    "## Aspect Ratio Grouping\n",
    "\n",
    "To speed up training by grouping images with similar aspect ratios, implement a `get_height_and_width` method. This method should return the height and width of the image. If this method is not implemented, `__getitem__` will be used to load the image during training, which can be slower.\n",
    "\n",
    "## Writing a Custom Dataset for Penn-Fudan\n",
    "\n",
    "Let‚Äôs create a custom dataset for the Penn-Fudan dataset. First, download the dataset and extract the zip file:\n",
    "\n",
    "```bash\n",
    "wget https://www.cis.upenn.edu/~jshi/ped_html/PennFudanPed.zip -P data\n",
    "cd data && unzip PennFudanPed.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e233198-a7cb-4130-bb90-8df0b936d4ec",
   "metadata": {},
   "source": [
    "The folder structure should look like this:\n",
    "```\n",
    "PennFudanPed/\n",
    "  PedMasks/\n",
    "    FudanPed00001_mask.png\n",
    "    FudanPed00002_mask.png\n",
    "    FudanPed00003_mask.png\n",
    "    ...\n",
    "  PNGImages/\n",
    "    FudanPed00001.png\n",
    "    FudanPed00002.png\n",
    "    FudanPed00003.png\n",
    "    ...\n",
    "```\n",
    "Each image in the PNGImages/ folder corresponds to a mask in the PedMasks/ folder. The images contain pedestrians, and the masks outline the exact shape of the pedestrians in the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c96043-f2a8-4594-90e1-ec4b1de4e82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision.io import read_image\n",
    "\n",
    "\n",
    "image = read_image(\"data/PennFudanPed/PNGImages/FudanPed00046.png\")\n",
    "mask = read_image(\"data/PennFudanPed/PedMasks/FudanPed00046_mask.png\")\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(121)\n",
    "plt.title(\"Image\")\n",
    "plt.imshow(image.permute(1, 2, 0))\n",
    "plt.subplot(122)\n",
    "plt.title(\"Mask\")\n",
    "plt.imshow(mask.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a424c09f-55a2-4ca9-934c-791300414407",
   "metadata": {},
   "source": [
    "## Custom Dataset for Image Segmentation and Object Detection\n",
    "\n",
    "Each image in the dataset corresponds to a segmentation mask, where different colors in the mask represent different instances. To process this data, we can define a custom `torch.utils.data.Dataset` class. This class will wrap the images, bounding boxes, and masks into `torchvision.tv_tensors.TVTensor` classes, allowing us to apply torchvision's built-in transformations for object detection and segmentation tasks.\n",
    "\n",
    "### Using `torchvision.tv_tensors`\n",
    "\n",
    "- **Image**: Images will be wrapped in `torchvision.tv_tensors.Image`, allowing them to be treated as tensors.\n",
    "- **Bounding Boxes**: Bounding boxes are wrapped in `torchvision.tv_tensors.BoundingBoxes`, which is used for object detection tasks.\n",
    "- **Masks**: Masks will be wrapped in `torchvision.tv_tensors.Mask`, used for segmentation tasks.\n",
    "\n",
    "Since `torchvision.tv_tensors.TVTensor` classes are subclasses of `torch.Tensor`, they inherit the standard `torch.Tensor` API, making it easy to apply any tensor operations and transformations.\n",
    "\n",
    "For more information on `torchvision.tv_tensors`, refer to the [documentation](https://pytorch.org/vision/main/auto_examples/transforms/plot_transforms_getting_started.html#what-are-tvtensors).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8060a8ea-22d5-4078-9270-fce01a7fe3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from torchvision.io import read_image\n",
    "from torchvision.ops.boxes import masks_to_boxes\n",
    "from torchvision import tv_tensors\n",
    "from torchvision.transforms.v2 import functional as F\n",
    "\n",
    "\n",
    "class PennFudanDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, transforms):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        # load all image files, sorting them to\n",
    "        # ensure that they are aligned\n",
    "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"PNGImages\"))))\n",
    "        self.masks = list(sorted(os.listdir(os.path.join(root, \"PedMasks\"))))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load images and masks\n",
    "        img_path = os.path.join(self.root, \"PNGImages\", self.imgs[idx])\n",
    "        mask_path = os.path.join(self.root, \"PedMasks\", self.masks[idx])\n",
    "        img = read_image(img_path)\n",
    "        mask = read_image(mask_path)\n",
    "        # instances are encoded as different colors\n",
    "        obj_ids = torch.unique(mask)\n",
    "        # first id is the background, so remove it\n",
    "        obj_ids = obj_ids[1:]\n",
    "        num_objs = len(obj_ids)\n",
    "\n",
    "        # split the color-encoded mask into a set\n",
    "        # of binary masks\n",
    "        masks = (mask == obj_ids[:, None, None]).to(dtype=torch.uint8)\n",
    "\n",
    "        # get bounding box coordinates for each mask\n",
    "        boxes = masks_to_boxes(masks)\n",
    "\n",
    "        # there is only one class\n",
    "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        image_id = idx\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        # Wrap sample and targets into torchvision tv_tensors:\n",
    "        img = tv_tensors.Image(img)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = tv_tensors.BoundingBoxes(boxes, format=\"XYXY\", canvas_size=F.get_size(img))\n",
    "        target[\"masks\"] = tv_tensors.Mask(masks)\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a671cda-c7f6-4f9b-b025-9bcf1cddebe4",
   "metadata": {},
   "source": [
    "That's all for the dataset. Now let's define a model that can perform\n",
    "predictions on this dataset.\n",
    "\n",
    "Defining your model\n",
    "===================\n",
    "\n",
    "In this tutorial, we will be using [Mask\n",
    "R-CNN](https://arxiv.org/abs/1703.06870), which is based on top of\n",
    "[Faster R-CNN](https://arxiv.org/abs/1506.01497). Faster R-CNN is a\n",
    "model that predicts both bounding boxes and class scores for potential\n",
    "objects in the image.\n",
    "\n",
    "![image](https://pytorch.org/tutorials/_static/img/tv_tutorial/tv_image03.png)\n",
    "\n",
    "Mask R-CNN adds an extra branch into Faster R-CNN, which also predicts\n",
    "segmentation masks for each instance.\n",
    "\n",
    "![image](https://pytorch.org/tutorials/_static/img/tv_tutorial/tv_image04.png)\n",
    "\n",
    "There are two common situations where one might want to modify one of\n",
    "the available models in TorchVision Model Zoo. The first is when we want\n",
    "to start from a pre-trained model, and just finetune the last layer. The\n",
    "other is when we want to replace the backbone of the model with a\n",
    "different one (for faster predictions, for example).\n",
    "\n",
    "Let's go see how we would do one or another in the following sections.\n",
    "\n",
    "1 - Finetuning from a pretrained model\n",
    "--------------------------------------\n",
    "\n",
    "Let's suppose that you want to start from a model pre-trained on COCO\n",
    "and want to finetune it for your particular classes. Here is a possible\n",
    "way of doing it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918c7433-e170-412e-9232-5eee05aac8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "# load a model pre-trained on COCO\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "\n",
    "# replace the classifier with a new one, that has\n",
    "# num_classes which is user-defined\n",
    "num_classes = 2  # 1 class (person) + background\n",
    "# get number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987a4581-468c-4b33-b7c4-27616ade5eb5",
   "metadata": {},
   "source": [
    "2 - Modifying the model to add a different backbone\n",
    "===================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b098512-93b8-4a67-8eb3-d8fd03f1f4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "\n",
    "# load a pre-trained model for classification and return\n",
    "# only the features\n",
    "backbone = torchvision.models.mobilenet_v2(weights=\"DEFAULT\").features\n",
    "# ``FasterRCNN`` needs to know the number of\n",
    "# output channels in a backbone. For mobilenet_v2, it's 1280\n",
    "# so we need to add it here\n",
    "backbone.out_channels = 1280\n",
    "\n",
    "# let's make the RPN generate 5 x 3 anchors per spatial\n",
    "# location, with 5 different sizes and 3 different aspect\n",
    "# ratios. We have a Tuple[Tuple[int]] because each feature\n",
    "# map could potentially have different sizes and\n",
    "# aspect ratios\n",
    "anchor_generator = AnchorGenerator(\n",
    "    sizes=((32, 64, 128, 256, 512),),\n",
    "    aspect_ratios=((0.5, 1.0, 2.0),)\n",
    ")\n",
    "\n",
    "# let's define what are the feature maps that we will\n",
    "# use to perform the region of interest cropping, as well as\n",
    "# the size of the crop after rescaling.\n",
    "# if your backbone returns a Tensor, featmap_names is expected to\n",
    "# be [0]. More generally, the backbone should return an\n",
    "# ``OrderedDict[Tensor]``, and in ``featmap_names`` you can choose which\n",
    "# feature maps to use.\n",
    "roi_pooler = torchvision.ops.MultiScaleRoIAlign(\n",
    "    featmap_names=['0'],\n",
    "    output_size=7,\n",
    "    sampling_ratio=2\n",
    ")\n",
    "\n",
    "# put the pieces together inside a Faster-RCNN model\n",
    "model = FasterRCNN(\n",
    "    backbone,\n",
    "    num_classes=2,\n",
    "    rpn_anchor_generator=anchor_generator,\n",
    "    box_roi_pool=roi_pooler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4053afeb-c1d4-478b-9863-59d05408c28b",
   "metadata": {},
   "source": [
    "Object detection and instance segmentation model for PennFudan Dataset\n",
    "======================================================================\n",
    "\n",
    "In our case, we want to finetune from a pre-trained model, given that\n",
    "our dataset is very small, so we will be following approach number 1.\n",
    "\n",
    "Here we want to also compute the instance segmentation masks, so we will\n",
    "be using Mask R-CNN:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b611d5d-e83c-46dd-992b-22ec236f4d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "\n",
    "def get_model_instance_segmentation(num_classes):\n",
    "    # load an instance segmentation model pre-trained on COCO\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "\n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # now get the number of input features for the mask classifier\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    # and replace the mask predictor with a new one\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
    "        in_features_mask,\n",
    "        hidden_layer,\n",
    "        num_classes\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df514f59-c062-44ce-b32b-58df1dbdcc34",
   "metadata": {},
   "source": [
    "That's it, this will make `model` be ready to be trained and evaluated\n",
    "on your custom dataset.\n",
    "\n",
    "Putting everything together\n",
    "===========================\n",
    "\n",
    "In `references/detection/`, we have a number of helper functions to\n",
    "simplify training and evaluating detection models. Here, we will use\n",
    "`references/detection/engine.py` and `references/detection/utils.py`.\n",
    "Just download everything under `references/detection` to your folder and\n",
    "use them here. On Linux if you have `wget`, you can download them using\n",
    "below commands:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf447e6-f0a5-40fd-9c25-01b57e7b40d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76318117-72be-4974-8934-f92747b8d501",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/engine.py\")\n",
    "os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/utils.py\")\n",
    "os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_utils.py\")\n",
    "os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_eval.py\")\n",
    "os.system(\"wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/transforms.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da22d06-d6b1-403a-b982-73dde50f3720",
   "metadata": {},
   "source": [
    "Let's write some helper functions for data augmentation /\n",
    "transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83333277-8eed-4725-b30d-72fe148331e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2 as T\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    transforms.append(T.ToDtype(torch.float, scale=True))\n",
    "    transforms.append(T.ToPureTensor())\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f99867-acbb-4aef-8b6f-6b8f4b054df0",
   "metadata": {},
   "source": [
    "Testing `forward()` method (Optional)\n",
    "=====================================\n",
    "\n",
    "Before iterating over the dataset, it\\'s good to see what the model\n",
    "expects during training and inference time on sample data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb83b9d-df97-4572-b9aa-3cfc6fcbf07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "dataset = PennFudanDataset('data/PennFudanPed', get_transform(train=True))\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    collate_fn=utils.collate_fn\n",
    ")\n",
    "\n",
    "# For Training\n",
    "images, targets = next(iter(data_loader))\n",
    "images = list(image for image in images)\n",
    "targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "output = model(images, targets)  # Returns losses and detections\n",
    "print(output)\n",
    "\n",
    "# For inference\n",
    "model.eval()\n",
    "x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
    "predictions = model(x)  # Returns predictions\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cffb23-6065-47cd-b387-95f9469517a0",
   "metadata": {},
   "source": [
    "Let's now write the main function which performs the training and the\n",
    "validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b154ae87-c76d-4d16-b068-22f2a2224662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine import train_one_epoch, evaluate\n",
    "\n",
    "# train on the GPU or on the CPU, if a GPU is not available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# our dataset has two classes only - background and person\n",
    "num_classes = 2\n",
    "# use our dataset and defined transformations\n",
    "dataset = PennFudanDataset('data/PennFudanPed', get_transform(train=True))\n",
    "dataset_test = PennFudanDataset('data/PennFudanPed', get_transform(train=False))\n",
    "\n",
    "# split the dataset in train and test set\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "dataset = torch.utils.data.Subset(dataset, indices[:-50])\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])\n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    collate_fn=utils.collate_fn\n",
    ")\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=utils.collate_fn\n",
    ")\n",
    "\n",
    "# get the model using our helper function\n",
    "model = get_model_instance_segmentation(num_classes)\n",
    "\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(\n",
    "    params,\n",
    "    lr=0.005,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.0005\n",
    ")\n",
    "\n",
    "# and a learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=3,\n",
    "    gamma=0.1\n",
    ")\n",
    "\n",
    "# let's train it just for 2 epochs\n",
    "num_epochs = 2\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train for one epoch, printing every 10 iterations\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    # evaluate on the test dataset\n",
    "    evaluate(model, data_loader_test, device=device)\n",
    "\n",
    "print(\"That's it!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5446b918-5fbc-44d2-9bce-3691eb494f89",
   "metadata": {},
   "source": [
    "So after one epoch of training, we obtain a COCO-style mAP \\> 50, and a\n",
    "mask mAP of 65.\n",
    "\n",
    "But what do the predictions look like? Let's take one image in the\n",
    "dataset and verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552c2211-6bf8-4bb8-9213-ad56383bb8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.utils import draw_bounding_boxes, draw_segmentation_masks\n",
    "\n",
    "\n",
    "image = read_image(\"data/PennFudanPed/PNGImages/FudanPed00046.png\")\n",
    "eval_transform = get_transform(train=False)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x = eval_transform(image)\n",
    "    # convert RGBA -> RGB and move to device\n",
    "    x = x[:3, ...].to(device)\n",
    "    predictions = model([x, ])\n",
    "    pred = predictions[0]\n",
    "\n",
    "\n",
    "image = (255.0 * (image - image.min()) / (image.max() - image.min())).to(torch.uint8)\n",
    "image = image[:3, ...]\n",
    "pred_labels = [f\"pedestrian: {score:.3f}\" for label, score in zip(pred[\"labels\"], pred[\"scores\"])]\n",
    "pred_boxes = pred[\"boxes\"].long()\n",
    "output_image = draw_bounding_boxes(image, pred_boxes, pred_labels, colors=\"red\")\n",
    "\n",
    "masks = (pred[\"masks\"] > 0.7).squeeze(1)\n",
    "output_image = draw_segmentation_masks(output_image, masks, alpha=0.5, colors=\"blue\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(output_image.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e4c032-fe5f-4b8b-be93-76573544f2e9",
   "metadata": {},
   "source": [
    "## Parallel Training on multiple cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e754e63-1ee8-4592-9fc0-99153c3f8e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Simple Neural Network Model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)  # input layer (784) -> hidden layer (128)\n",
    "        self.fc2 = nn.Linear(128, 10)   # hidden layer (128) -> output layer (10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Check if multiple GPUs are available and use them\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleNN().to(device)\n",
    "\n",
    "# Use DataParallel for multi-GPU training\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    model = nn.DataParallel(model)  # Wrap the model to parallelize across GPUs\n",
    "\n",
    "# Generate some random data for training\n",
    "# Here we're creating a dummy dataset\n",
    "x_train = torch.randn(60000, 784)  # 60,000 samples, 784 features (e.g., flattened 28x28 images)\n",
    "y_train = torch.randint(0, 10, (60000,))  # 60,000 labels, with 10 possible classes\n",
    "\n",
    "# Create a DataLoader for batching\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Optimizer and Loss Function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Iterate over batches of data\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics (every 100 batches)\n",
    "        running_loss += loss.item()\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {running_loss/100:.4f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11582a89-cc1c-49c3-9166-1df4bf97c0d0",
   "metadata": {},
   "source": [
    "Material taken from https://pytorch.org/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
